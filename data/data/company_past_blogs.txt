ezML Swim AI v1 - Auto Swim Split Detection for Swimming Analysis
Sean Dorje

Sean Dorje

Swim AI Auto Swim Split
In the world of competitive swimming, every millisecond counts. 




With olympic swimming on the display at the Paris Olympics in 2024 and international glory on the line, we see how coaches and athletes are constantly seeking ways to gain an edge, refine techniques, and optimize performance, especially when races are coming down to the hundreths of a second.

Enter Swim AI v1, ezML's cutting-edge solution that's revolutionizing how swimmers and coaches approach time splits and pacing strategies.

The Power of Precise Splits
Distance splits have long been a crucial tool in swimming analysis. They provide invaluable data on a swimmer's pace, endurance, and overall race strategy. However, traditional methods of capturing splits often rely on manual timing, which can be prone to human error and inconsistency.

Swim AI v1 changes the game with its automatic distance split detection feature. This innovative technology allows users to place custom time split lines at any point along a swimming lane. Once set, our advanced computer vision algorithms take over, tracking swimmers with unprecedented accuracy and automatically capturing split times as they cross these virtual lines.



Key Features of Swim AI v1's Auto Split Detection:
Custom Placement: Place virtual split lines anywhere along the swimming lane to capture distance splits. This enables flexible and focused analysis on specific race segements (e.g., first 15m after a turn)

Advanced Tracking: Uses state-of-the-art computer vision algorithms to track swimmers accurately

Automatic Capture: Instantly records split times as swimmers cross virtual lines

Real-time Feedback: Provides instant, accurate split times for immediate strategy adjustments. 

Precision in Challenging Conditions: Accounts for splash, underwater movements, and water refraction

Multi-Swimmer Tracking (coming soon): Consistently identifies and follows individual swimmers, even in crowded lanes or relays. Currently supporting one swimmer per lane. 


Highlight: State-of-the-Art Computer Vision Tracking
At the heart of Swim AI v1 is our novel, state-of-the-art computer vision tracking algorithm. This sophisticated system is designed specifically for the unique challenges of tracking swimmers in water, accounting for factors like splash, underwater movements, and the refractive properties of water.

Our algorithm can consistently identify and follow individual swimmers, even in crowded lanes or during relay events. This level of precision ensures that every split time captured is accurate and reliable, providing coaches and athletes with data they can trust.

Customization for Targeted Analysis
One of the standout features of Swim AI v1 is its flexibility. Users can place split lines at any point in the lane, allowing for highly customized analysis. Want to focus on the first 15 meters after a turn? No problem. Interested in comparing the second and third 25m of a 100m race? Swim AI v1 makes it simple.

This customization empowers coaches to analyze specific aspects of a swimmer's performance, identifying areas for improvement with pinpoint accuracy.

Benefits for Swimmers and Coaches:
Developing Olympic-Caliber Pacing Strategies 

Swim AI v1's automatic split detection revolutionizes pacing approaches. By providing instant, accurate feedback, swimmers can experiment with and visualize different pacing strategies in real-time. This accelerates the learning process, helping athletes quickly internalize effective techniques. 

Olympic history highlights the critical nature of precise pacing: 

Beijing 2008: Michael Phelps' meticulous split-time strategy led to a 0.01-second victory in the 200m butterfly. 

Rio 2016: Kyle Chalmers' negative split approach clinched gold in the 100m freestyle. 

Swim AI v1 brings this level of strategic insight to swimmers at all levels, enabling the development of winning race strategies.



Enhancing Technical Performance and Race Analysis 

The precise data from Swim AI v1 offers unprecedented insights into a swimmer's performance across different race segments. Coaches and athletes can:

Identify areas where technique breaks down or efficiency is lost

Pinpoint endurance issues or fatigue-related technical flaws

Leverage a swimmer's strengths in race strategy

Implement targeted training interventions 

This level of detailed analysis allows for a scientific approach to training and racing, moving beyond subjective assessments to data-driven improvements.



Achieving Significant Time Improvements 

By combining strategic pacing and technical refinement, Swim AI v1 aims to help swimmers:

Distribute energy optimally throughout races

Avoid early burnout and Finish strong

Shave crucial seconds off in longer events

Gain fractions of a second in sprints - often the difference between podium and participation 

This powerful tool unlocks a swimmer's full potential, turning consistent training and intelligent pacing into tangible competitive results, whether it's at a local meet or on the Olympic stage.




Swim AI is Drastically Expanding 🚀
As we continue to refine and expand Swim AI, we're excited about the potential for even more advanced analysis and insights. Future versions may incorporate additional metrics, such as stroke efficiency analysis and turn performance, to provide an even more comprehensive view of a swimmer's performance.

Swim AI v1's automatic time split detection is more than just a convenient feature – it's a powerful tool that's changing how swimmers train and compete. By providing accurate, customizable, and instant split data, we're empowering athletes and coaches to make data-driven decisions that lead to faster times and better performances.

Whether you're a coach looking to take your team to the next level, or a swimmer aiming for personal bests, Swim AI v1 offers the insights and accuracy you need to succeed in the pool. Experience the future of swim analysis – try Swim AI v1 today.



Contact us for a demo 
Meet directly with the founders of ezML or learn more about how Swim AI v1 can enhance your swimming program :) 
https://calendly.com/ezml/consultation



Computer Vision AI for Tennis Clubs: A High-end Experience for Players, Coaches, and Members.
Sean Dorje

Sean Dorje


Intro to Computer Vision in Sports
computer vision in sports
Sports is a special, indispensable, and unique industry that serves as one of the essential backbones of countries throughout history like the US. AI is not going to replace sports, coaches, players, fans, or anything in between. But it sure as hell can improve the field and has shown so in the past decade for large orgs & leagues.

But now with a camera and a sprinkle of software, smaller sports club owners around the country are able to use AI at their sports clubs to enhance coach, player, and member experiences.

All this thanks to the integration of a cutting-edge technology called computer vision (CV). For those new to this term, computer vision is a field of artificial intelligence that enables computers and systems to derive meaningful information from images, videos, and other visual inputs.

In the realm of sports, and tennis in particular, this technology is providing unprecedented tools for player development, game analysis, and enhancing the overall club experience.


The Power of Computer Vision in Sports
computer vision cnn
In sports, computer vision technology is used to analyze video footage to track players and objects, assess performance, and provide analytics that were once impossible to capture without extensive manual effort and expertise. This innovative approach allows for real-time feedback, detailed performance reviews, and even injury prevention strategies by analyzing athletes' movements and identifying potential risks.


Transforming Tennis Clubs with Computer Vision
computer vision in tennis clubs
Building on this foundation, computer vision is greatly improving tennis by unlocking deep insights into player performance and analytics such as serve speed, shot placement accuracy, forehand/backhand effectiveness, etc. It also helps automate tasks like match scoring, line calling, and player evaluations. Let's explore some of the benefits:


Automated Highlights for Tennis Players
auto highlights for tennis
Computer vision AI analyzes live tennis match footage, automatically detecting key moments. The system identifies crucial points, impressive rallies, powerful serves, and skilful shots. It recognizes player reactions, crowd excitement, and changes in score. By tracking ball trajectories and player movements, it captures match-defining plays and exceptional athletic feats. The AI compiles these moments into a highlight reel in real-time, creating instant, engaging content that showcases the match's most exciting and significant moments without human intervention.


In-Depth Performance Analytics
Imagine a world where every aspect of a player's game is quantified and analyzed — from serve speeds and shot accuracy to movement patterns and rally lengths. Computer vision makes this possible, offering players and coaches a treasure trove of data to hone skills, strategize gameplay, and track development over time.


AI-Driven Matchmaking for Players
AI matchmaking for tennis
Finding the perfect match for a game can be challenging, but computer vision simplifies this by analyzing players' skills and styles to create the most competitive and enjoyable matchups. This ensures that every game is not just a match but a step towards improvement and enjoyment.


Benefits Beyond the Court
Operational Efficiency: Streamline club operations with automated systems for managing bookings, analyzing court usage, and maintaining facilities.

Safety and Security: Enhance safety protocols by monitoring facilities in real-time to prevent unauthorized access and quickly respond to incidents.

Member & Media Engagement: Foster a stronger club community by showcasing player highlights on social media, hosting data-driven tournaments, and creating a more interactive and engaging environment for members.


The Current Bottleneck for Computer Vision Tennis Solutions



As a result of these great features, many leagues and teams such as many ATP tour events, Grand Slam, and ITF facilities have been adopting computer vision. HOWEVER, there are extremely limited solutions providers that COMPLETELY leave out tennis clubs right now.

High-end systems like Hawk-Eye offer advanced CV tennis analytics but rely on complex infrastructure requirements like high speed cameras and dedicated servers which can easily go up to multi 6-figures. This unreasonably high price can be sustained by larger orgs but heavily limits accessibility for local clubs. 

Meanwhile, there's widely accessible consumer apps like Swing Vision that bring CV tennis analytics to personal devices, BUT with compromises in accuracy due to on-device processing limitations. And these consumer apps charge individual players that play in tennis clubs, giving 0 benefit to club owners themselves.

This underscores the need for solutions in the hands of tennis club owners that can balance professional-grade insights with user-friendly, cost-effective accessibility, enabling widespread adoption of CV technology in tennis.


Why Choose ezML?
At ezML, we're bringing powerful and affordable computer vision into the hands of tennis club owners to provide for their members because that's where we believe it's most effective.

Our team is currently looking for club design partners interested in powering their club with computer vision integration. Partner with us to become a leader in sports technology innovation. Our solutions are designed to be:

Customizable: Tailored to fit the unique needs of your club and its members.

User-friendly: Accessible for all, regardless of technical expertise.

Scalable: Grows with your club, ensuring your technology investment is future-proof.

Cost-effective: Delivers high ROI by enhancing member satisfaction and operational efficiency.


Take the First Step Towards the Future
The integration of computer vision technology in your tennis club is not just about staying ahead of the curve; it's about setting a new standard for excellence in member experience and club operations. ezML is here to make this transition smooth, effective, and transformative.

Are you ready to revolutionize your tennis club with the power of computer vision? Schedule a completely free consultation with me and my co-founder and chat with us. Even if you're just a bit curious. We love exchanging insights with anyone in sports! Find a time here on our calendly.

Have a blessed day and thanks for reading my handwritten blog ✌️

Florence-2: Novel Vision Language Model by Microsoft
Sean Dorje

Sean Dorje


Welcome to the realm of Florence-2, Microsoft Azure AI's trailblazing model in computer vision. This comprehensive guide delves into Florence-2's innovative approach, setting a new standard in vision AI with its unified, prompt-based architecture for a broad spectrum of vision and vision-language tasks.


A New Approach: Rethinking Vision Model Pre-training
Pioneering Universal Representation Learning
Florence-2 represents a paradigm shift in vision model pre-training. Moving beyond the constraints of traditional supervised, self-supervised, and weakly supervised learning paradigms, Florence-2 brings a unified approach to tackle a wide array of vision tasks using a single model architecture. This shift addresses the need for adaptability and a comprehensive understanding of visual data beyond single-task learning frameworks.

Flowchart depicting the evolution from traditional pre-training paradigms to Florence-2's unified approach

Comprehensive Multitask Learning with Florence-2
Mastering Spatial and Semantic Granularity
Florence-2's comprehensive multitask learning objectives are designed to address various aspects of visual comprehension, aligning with spatial hierarchy and semantic granularity. It incorporates image-level understanding tasks for high-level semantics, region/pixel-level recognition tasks for detailed object localization, and fine-grained visual-semantic alignment tasks. This multifaceted approach enables Florence-2 to handle different levels of detail and semantic understanding, ultimately learning a universal representation for vision.


Inside Florence-2: Unifying Vision and Language
The Power of Sequence-to-Sequence Learning
Florence-2 employs a sequence-to-sequence learning paradigm, integrating tasks under a common language modeling objective. It takes images coupled with text prompts to generate text-based results. This structure allows Florence-2 to handle various vision tasks in a unified manner, from image classification to complex captioning and visual grounding.


Data Engine: The Foundation of Florence-2
Building a Large-Scale Multitask Dataset
To train Florence-2, a comprehensive dataset named FLD-5B was developed. This dataset includes 126 million images with over 500 million text annotations, 1.3 billion text-region annotations, and 3.6 billion text-phrase-region annotations. The diversity and scale of FLD-5B provide a rich foundation for Florence-2 to learn and excel across various vision tasks.

Infographic highlighting the key components and scale of the FLD-5B dataset
Dataset Analysis: Understanding FLD-5B
Exploring the Depth of Annotations
FLD-5B sets itself apart with its detailed annotation statistics, semantic coverage, and spatial coverage. Each image in FLD-5B is annotated with text, region-text pairs, and text-phrase-region triplets, offering diverse levels of granularity. This enables more comprehensive visual understanding tasks and positions FLD-5B ahead of existing datasets used for training foundation models.

A visual breakdown of FLD-5B's annotation types

Experiments with Florence-2: Proving Its Mettle

Demonstrating Versatility and Advanced Performance
Florence-2's training on FLD-5B enabled it to learn a universal image representation. The experiments conducted on Florence-2 encompassed evaluating its zero-shot performance, adaptability with additional supervised data, and performance in downstream tasks. These tests proved Florence-2's ability to handle multiple tasks without extra fine-tuning, achieving competitive state-of-the-art performance, and demonstrating the superiority of its pre-training method over previous approaches.

Zero-Shot Evaluation: Florence-2's Impressive Versatility for Handling Unseen Tasks
In an exciting part of the research, Florence-2 was put through a "zero-shot" evaluation. This test was all about seeing how well the model could handle tasks it wasn't directly trained to do. Here's what stood out:

Remarkable Image Understanding: On the COCO caption benchmark, a standard test for image understanding, Florence-2-L (a larger version of the model) scored impressively high. It did this using far fewer parameters than much larger models, showcasing its efficiency.

Excelling in Complex Tasks: For more detailed tasks like understanding and describing specific regions in images, Florence-2-L not only did well but set new records in performance. This shows its ability to grasp complex visual details.

General Versatility: The model demonstrated strong adaptability across various types of tasks, from image captioning to answering questions about images, without needing special training for each.



This zero-shot evaluation reveals that Florence-2 isn't just good at the tasks it's trained for; it's also quick to adapt to new challenges. This versatility makes it a standout model, ready for a wide range of real-world applications.

Here's a breakdown of the downstream tasks fine-tuning experiment with Florence-2:
Choice of Model: For these tests, they used a smaller version of Florence-2 with about 80 million parameters. This choice was made to ensure a fair comparison with other similar models.

Selected Tasks for Testing:

Object Detection and Segmentation: The team tested Florence-2 on two key tasks using the COCO dataset. These tasks were:

Object detection and instance segmentation with a method called Mask R-CNN.

Object detection with another method known as DINO.

Training and Evaluation Details:

The model was trained using images from the COCO dataset's 2017 training set and then evaluated using the dataset's 2017 validation set. For the Mask R-CNN method, they followed a standard training schedule without any additional tricks or techniques. This straightforward approach meant that any success could be attributed to Florence-2’s pre-training. Similarly, for the DINO method, the team kept the training simple and standard, focusing on demonstrating the model's inherent capabilities.

What They Found:

The results were quite remarkable. Despite the simplified training approach, Florence-2 performed exceptionally well in these specific tasks.

This success indicated that the comprehensive pre-training of Florence-2 had effectively prepared it to handle complex and varied visual tasks with ease.

Charts and graphs showing Florence-2's performance in various experimental settings

Conclusion: Envisioning the Future with Florence-2
Florence-2, with its innovative approach and the extensive capabilities demonstrated by the FLD-5B dataset, is redefining the boundaries of vision AI. Its ability to understand and interpret images through a unified approach opens new horizons for AI applications in various industries, making it a pivotal development in the journey of computer vision.

